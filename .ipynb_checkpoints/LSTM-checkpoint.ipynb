{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "b0d76d8c48769608"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T22:36:08.884639Z",
     "start_time": "2024-12-01T22:36:08.876632Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Helper functions",
   "id": "c938e5a2e1fa807f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:36:08.919857Z",
     "start_time": "2024-12-01T22:36:08.899653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_data(prices):\n",
    "    prices = prices.values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_prices = scaler.fit_transform(prices)\n",
    "    return scaled_prices, scaler\n",
    "\n",
    "def create_sequences(data, dates, look_back):\n",
    "    X, y, y_dates = [], [], []\n",
    "    for i in range(look_back, len(data)):\n",
    "        X.append(data[i - look_back:i])\n",
    "        y.append(data[i])\n",
    "        y_dates.append(dates[i])\n",
    "    return np.array(X), np.array(y), y_dates\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(units=50, return_sequences=False, input_shape=input_shape),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def generate_signals(predictions, dates, threshold):\n",
    "    df_predictions = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'prediction': predictions.squeeze()\n",
    "    })\n",
    "    df_predictions['date'] = pd.to_datetime(df_predictions['date'])\n",
    "    df_predictions.sort_values('date', inplace=True)\n",
    "    df_predictions.reset_index(drop=True, inplace=True)\n",
    "    df_predictions['next_day_prediction'] = df_predictions['prediction'].shift(-1)\n",
    "    df_predictions['predicted_change'] = df_predictions['next_day_prediction'] - df_predictions['prediction']\n",
    "    df_predictions['pct_change'] = df_predictions['predicted_change'] / df_predictions['prediction']\n",
    "    df_predictions.dropna(subset=['next_day_prediction'], inplace=True)\n",
    "\n",
    "    def get_signal(row):\n",
    "        if row['pct_change'] > threshold:\n",
    "            return 'buy'\n",
    "        elif row['pct_change'] < -threshold:\n",
    "            return 'sell'\n",
    "        else:\n",
    "            return 'hold'\n",
    "\n",
    "    df_predictions['signal'] = df_predictions.apply(get_signal, axis=1)\n",
    "    return df_predictions[['date', 'signal']]\n"
   ],
   "id": "1b40b87935dc4264",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Read the List of S&P 500 Stocks",
   "id": "ac18cc04f3cea5e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:36:08.989104Z",
     "start_time": "2024-12-01T22:36:08.978412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directory containing the CSV files\n",
    "csv_directory = 'all_sp500_csvs_2010-24'\n",
    "\n",
    "# List of tickers based on the CSV filenames\n",
    "tickers = [filename.replace('.csv', '') for filename in os.listdir(csv_directory) if filename.endswith('.csv')]\n",
    "\n",
    "# Sort the tickers\n",
    "tickers.sort()\n"
   ],
   "id": "6b5056b8f8528c04",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define Parameters",
   "id": "6c0b048eef093003"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:36:09.055629Z",
     "start_time": "2024-12-01T22:36:09.048154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define parameters\n",
    "start_date = '2010-01-01'\n",
    "split_date = '2022-12-31'  # Adjust as needed\n",
    "end_date = '2023-10-20'     # Adjust to the latest available date\n",
    "look_back = 10\n",
    "threshold = 0.01  # Adjust the threshold as needed\n"
   ],
   "id": "7c46949dbf4d36ee",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Automate the LSTM Model for Each Stock",
   "id": "2c725e5ac59804cd"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-01T22:36:09.118821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize dictionaries to store signals\n",
    "signals_dict = {}\n",
    "\n",
    "for ticker in tqdm(tickers):\n",
    "    try:\n",
    "        print(f\"\\nProcessing ticker: {ticker}\")\n",
    "        # Read data from CSV, skipping the first three rows\n",
    "        csv_path = os.path.join(csv_directory, f\"{ticker}.csv\")\n",
    "        data = pd.read_csv(csv_path, skiprows=3, header=None)\n",
    "        data.columns = ['Date', 'Price', 'Adj Close', 'Close', 'High', 'Low', 'Volume']\n",
    "        data['Date'] = pd.to_datetime(data['Date'])\n",
    "        data.set_index('Date', inplace=True)\n",
    "        data.sort_index(inplace=True)\n",
    "\n",
    "        # Convert the index to timezone-naive\n",
    "        data.index = data.index.tz_localize(None)\n",
    "\n",
    "        # Filter data based on start and end dates\n",
    "        data = data.loc[(data.index >= pd.to_datetime(start_date)) & (data.index <= pd.to_datetime(end_date))]\n",
    "\n",
    "        # Check if data is sufficient\n",
    "        if data.empty or len(data) < look_back + 1:\n",
    "            print(f\"Skipping {ticker}: insufficient data after filtering\")\n",
    "            continue  # Skip if insufficient data\n",
    "\n",
    "        # Print date range for debugging\n",
    "        print(f\"{ticker} data from {data.index.min().date()} to {data.index.max().date()}\")\n",
    "\n",
    "        # Preprocess data\n",
    "        scaled_prices, scaler = preprocess_data(data['Close'])\n",
    "        dates_all = data.index\n",
    "\n",
    "        # Create sequences\n",
    "        X, y, y_dates = create_sequences(scaled_prices, dates_all, look_back)\n",
    "\n",
    "        # Check if sequences are created\n",
    "        if len(X) == 0:\n",
    "            print(f\"Skipping {ticker}: no sequences created\")\n",
    "            continue\n",
    "\n",
    "        # Split into train and test based on dates\n",
    "        split_indices = np.where(pd.to_datetime(y_dates) >= pd.to_datetime(split_date))[0]\n",
    "        if len(split_indices) == 0:\n",
    "            print(f\"Skipping {ticker}: no data after split_date\")\n",
    "            continue\n",
    "        split_index = split_indices[0]\n",
    "        X_train, X_test = X[:split_index], X[split_index:]\n",
    "        y_train, y_test = y[:split_index], y[split_index:]\n",
    "        y_dates_train, y_dates_test = y_dates[:split_index], y_dates[split_index:]\n",
    "\n",
    "        if len(X_test) == 0:\n",
    "            print(f\"Skipping {ticker}: no test data after split_date\")\n",
    "            continue  # Skip if no test data\n",
    "\n",
    "        # Build and train model\n",
    "        print(f\"Training model for {ticker}\")\n",
    "        model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "        early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
    "        model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "        # Predict\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions_unscaled = scaler.inverse_transform(predictions)\n",
    "\n",
    "        # Generate signals\n",
    "        signals = generate_signals(predictions_unscaled, y_dates_test, threshold)\n",
    "        signals.set_index('date', inplace=True)\n",
    "        signals.rename(columns={'signal': ticker}, inplace=True)\n",
    "\n",
    "        # Store signals\n",
    "        signals_dict[ticker] = signals[[ticker]]\n",
    "        print(f\"Added signals for {ticker}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {e}\")\n",
    "        continue\n"
   ],
   "id": "c658380a880b5250",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/503 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ticker: A\n",
      "A data from 2010-01-04 to 2023-10-20\n",
      "Training model for A\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Aggregate the Signals into a DataFrame",
   "id": "46e08181cefd2275"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:22:01.799007Z",
     "start_time": "2024-12-01T22:22:01.794288Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5916224be36afaa9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:35:53.337638Z",
     "start_time": "2024-12-01T22:35:53.323412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Concatenate signals\n",
    "signal_df = pd.concat(signals_dict.values(), axis=1)\n",
    "signal_df.sort_index(inplace=True)\n"
   ],
   "id": "54aca7a314e746dc",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Filter the DataFrame for the Desired Date Range",
   "id": "c223ecd54bbf4295"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:35:54.720428Z",
     "start_time": "2024-12-01T22:35:54.709578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the date range for which we want the signals\n",
    "start_signal_date = '2023-01-01'\n",
    "end_signal_date = '2023-01-31'\n",
    "\n",
    "# Filter the signal DataFrame\n",
    "signal_df = signal_df.loc[(signal_df.index >= pd.to_datetime(start_signal_date)) & (signal_df.index <= pd.to_datetime(end_signal_date))]\n"
   ],
   "id": "18e05d2c56c6232d",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7848ca3934acc110"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:35:56.173792Z",
     "start_time": "2024-12-01T22:35:56.126227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the signal DataFrame\n",
    "print(signal_df)\n",
    "# Save the signal DataFrame to a CSV file\n",
    "signal_df.to_csv('signals_test_output.csv')\n",
    "\n",
    "print(\"Signals saved to 'signals_test_output.csv'\")\n"
   ],
   "id": "f25dfc739356de82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               A  AAPL  ABBV  ABNB   ABT  ACGL   ACN  ADBE   ADI   ADM\n",
      "date                                                                  \n",
      "2023-01-03  hold  hold  hold  hold  hold  hold  hold  hold  hold  hold\n",
      "2023-01-04  hold  hold  hold  hold  hold  hold  hold  hold  hold  sell\n",
      "2023-01-05  hold  hold  hold  hold  hold  hold  hold  hold  hold  sell\n",
      "2023-01-06  hold  hold  hold  hold  hold  hold  hold  hold  hold  sell\n",
      "2023-01-09  hold  hold  hold  hold  hold  hold  hold  hold  hold  sell\n",
      "2023-01-10  hold  hold  hold  hold  hold  hold  hold  hold  hold  hold\n",
      "2023-01-11  hold  hold  hold  hold  hold  hold  hold  hold  hold  hold\n",
      "2023-01-12  hold  hold  sell   buy  hold  hold   buy  hold  hold  hold\n",
      "2023-01-13  hold  hold  sell   buy  hold  hold  hold  hold  hold   buy\n",
      "2023-01-17  hold  hold  sell   buy  hold  hold  hold  hold  hold   buy\n",
      "2023-01-18  hold  hold  sell   buy  hold  hold  hold  hold  hold  hold\n",
      "2023-01-19  hold  hold  sell   buy  hold  hold  hold  hold  hold  hold\n",
      "2023-01-20  hold  hold  hold   buy  hold  hold  hold  hold  hold  sell\n",
      "2023-01-23  hold   buy  hold   buy  hold  hold  hold  hold  hold  sell\n",
      "2023-01-24  hold   buy  hold   buy  hold  hold  hold  hold  hold  hold\n",
      "2023-01-25  hold  hold  hold  hold  hold  hold  hold  hold  hold  hold\n",
      "2023-01-26  hold  hold  hold  hold  hold  hold  hold  hold  hold  hold\n",
      "2023-01-27  hold   buy  hold   buy  hold  hold  hold  hold  hold  hold\n",
      "2023-01-30  hold  hold  hold   buy  hold  hold  hold  hold  hold  hold\n",
      "2023-01-31  hold  hold  hold   buy  hold  hold  hold  hold  hold  hold\n",
      "Signals saved to 'signals_test_output.csv'\n"
     ]
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
