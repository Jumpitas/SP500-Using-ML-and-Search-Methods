{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "b0d76d8c48769608"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T17:07:24.893674Z",
     "start_time": "2024-12-04T17:07:24.888724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "id": "b092be5797ea0fb0",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Helper Functions\n",
    "\n",
    "These functions handle data preprocessing, signal generation, and model construction.\n"
   ],
   "id": "d19d717d05636c4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T17:07:24.955225Z",
     "start_time": "2024-12-04T17:07:24.947874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ## Helper Functions\n",
    "def create_sequences(data, dates, look_back):\n",
    "    \"\"\"\n",
    "    Converts time series data into sequences for LSTM input.\n",
    "\n",
    "    Parameters:\n",
    "    - data (numpy array): Scaled \"Close\" prices.\n",
    "    - dates (pandas DatetimeIndex): Corresponding dates.\n",
    "    - look_back (int): Number of previous time steps to include in each input sequence.\n",
    "\n",
    "    Returns:\n",
    "    - X (numpy array): Input sequences.\n",
    "    - y (numpy array): Target values.\n",
    "    - y_dates (list): Corresponding dates for each target value.\n",
    "    \"\"\"\n",
    "    X, y, y_dates = [], [], []\n",
    "    for i in range(look_back, len(data)):\n",
    "        X.append(data[i - look_back:i])\n",
    "        y.append(data[i])\n",
    "        y_dates.append(dates[i])\n",
    "    return np.array(X), np.array(y), y_dates\n",
    "\n",
    "\n",
    "def generate_signal(df, threshold=0.01):\n",
    "    \"\"\"\n",
    "    Generates trading signals ('buy', 'sell', 'hold') based on predicted price changes.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas DataFrame): DataFrame containing 'date', 'prediction', and 'actual' columns.\n",
    "    - threshold (float): Percentage change threshold to determine signals.\n",
    "\n",
    "    Returns:\n",
    "    - df_signals (pandas DataFrame): DataFrame with 'date', 'signal', 'prediction', and 'actual' columns.\n",
    "    \"\"\"\n",
    "    df['next_day_prediction'] = df['prediction'].shift(-1)\n",
    "    df['predicted_change'] = df['next_day_prediction'] - df['prediction']\n",
    "    df['pct_change'] = df['predicted_change'] / df['prediction']\n",
    "    df['next_day_actual'] = df['actual'].shift(-1)\n",
    "\n",
    "    def get_signal(row):\n",
    "        if row['pct_change'] > threshold:\n",
    "            return 'buy'\n",
    "        elif row['pct_change'] < -threshold:\n",
    "            return 'sell'\n",
    "        else:\n",
    "            return 'hold'\n",
    "\n",
    "    df['signal'] = df.apply(get_signal, axis=1)\n",
    "    df.dropna(subset=['next_day_prediction', 'next_day_actual'], inplace=True)\n",
    "\n",
    "    # Retain necessary columns for evaluation\n",
    "    return df[['date', 'signal', 'prediction', 'actual']]\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Builds and compiles an LSTM neural network model.\n",
    "\n",
    "    Parameters:\n",
    "    - input_shape (tuple): Shape of the input data (look_back, features).\n",
    "\n",
    "    Returns:\n",
    "    - model (keras Sequential): Compiled LSTM model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(units=50, return_sequences=False, input_shape=input_shape),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ],
   "id": "d824ea759911a683",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define Parameters and Prepare Directories\n",
    "\n",
    "Specify the list of stock tickers, threshold for signal generation, date ranges for training and testing, and create necessary directories for saving models and signals.\n"
   ],
   "id": "6472cfc9837c352f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T17:07:24.965061Z",
     "start_time": "2024-12-04T17:07:24.960232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the list of stock tickers you want to process\n",
    "tickers = [filename.replace('.csv', '') for filename in os.listdir('clean_csvs') if filename.endswith('.csv')]\n",
    "\n",
    "# Define a uniform threshold for all stocks\n",
    "uniform_threshold = 0.01  # 1% threshold\n",
    "\n",
    "# Define date ranges\n",
    "start_date = \"2010-01-01\"\n",
    "split_date = \"2023-12-31\"\n",
    "end_date = \"2024-01-31\"\n",
    "\n",
    "# Define look-back period\n",
    "look_back = 10  # Number of previous days to consider\n",
    "\n",
    "# Create directories for saving models and signals if they don't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('signals', exist_ok=True)"
   ],
   "id": "8bb24b846bbb41e9",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define Parameters",
   "id": "ec8924d00ec49855"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Automate the LSTM Model for Each Stock\n",
    "\n",
    "For each ticker:\n",
    "1. Download historical data.\n",
    "2. Preprocess the data.\n",
    "3. Train the LSTM model on training data.\n",
    "4. Make predictions on test data.\n",
    "5. Generate trading signals based on predictions.\n",
    "6. Compile all signals into a unified dataframe.\n"
   ],
   "id": "a06f73859ed01d34"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-04T17:07:25.022893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize an empty list to collect signals from all stocks\n",
    "all_signals = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"\\nProcessing {ticker}...\")\n",
    "\n",
    "    try:\n",
    "        # Download historical data\n",
    "        data_train = yf.download(ticker, start=start_date, end=split_date)\n",
    "        data_test = yf.download(ticker, start=split_date, end=end_date)\n",
    "\n",
    "        # Check if sufficient data is available\n",
    "        if len(data_train) < look_back + 1 or len(data_test) < look_back + 1:\n",
    "            print(f\"Insufficient data for {ticker}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Extract 'Close' prices and reshape\n",
    "        prices_train = data_train['Close'].values.reshape(-1, 1)\n",
    "        prices_test = data_test['Close'].values.reshape(-1, 1)\n",
    "\n",
    "        # Normalize the data using MinMaxScaler (fit on training data only)\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_prices_train = scaler.fit_transform(prices_train)\n",
    "        scaled_prices_test = scaler.transform(prices_test)\n",
    "\n",
    "        # Create sequences for training\n",
    "        dates_train = data_train.index\n",
    "        X_train, y_train, y_train_dates = create_sequences(scaled_prices_train, dates_train, look_back=look_back)\n",
    "\n",
    "        # Create sequences for testing\n",
    "        # For testing, use the last 'look_back' days from training + test data\n",
    "        combined_scaled = np.concatenate((scaled_prices_train[-look_back:], scaled_prices_test))\n",
    "        combined_dates = np.concatenate((dates_train[-look_back:], data_test.index))\n",
    "        X_test, y_test, y_test_dates = create_sequences(combined_scaled, combined_dates, look_back=look_back)\n",
    "\n",
    "        # Build the LSTM model\n",
    "        model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "        # Define Early Stopping callback\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=20,\n",
    "            batch_size=32,\n",
    "            validation_data=(X_test, y_test),\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Evaluate the model\n",
    "        train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "        test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"{ticker} - Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}\")\n",
    "\n",
    "        # Make predictions on test data\n",
    "        test_predictions = model.predict(X_test)\n",
    "\n",
    "        # Denormalize the predictions and actual values\n",
    "        test_predictions_unscaled = scaler.inverse_transform(test_predictions)\n",
    "        y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "\n",
    "        # Create a DataFrame for predictions\n",
    "        df_predictions = pd.DataFrame({\n",
    "            'date': y_test_dates,\n",
    "            'prediction': test_predictions_unscaled.squeeze(),\n",
    "            'actual': y_test_unscaled.squeeze()\n",
    "        })\n",
    "        df_predictions['date'] = pd.to_datetime(df_predictions['date'])\n",
    "        df_predictions.sort_values('date', inplace=True)\n",
    "        df_predictions.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Generate trading signals\n",
    "        df_signals = generate_signal(df_predictions, threshold=uniform_threshold)\n",
    "        df_signals['ticker'] = ticker  # Add ticker information\n",
    "\n",
    "        # Save individual ticker signals with predictions and actuals for detailed evaluation\n",
    "        df_signals.to_csv(f'signals/{ticker}_signals.csv', index=False)\n",
    "        print(f\"Signals for {ticker} saved to 'signals/{ticker}_signals.csv'.\")\n",
    "\n",
    "        # Append to all_signals list\n",
    "        all_signals.append(df_signals)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {ticker}: {e}\")"
   ],
   "id": "69ad5bf39525cb4b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing A...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m 16/110\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.1301 "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Aggregate the Signals into a Single CSV\n",
    "\n",
    "Combine the signals from all stocks into a single dataframe with dates as rows and tickers as columns. The content of each cell will be the generated signal (`buy`, `sell`, `hold`) for that stock on that date.\n"
   ],
   "id": "1ba048ae0d8065ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T19:07:13.327758Z",
     "start_time": "2024-12-04T19:07:13.314237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if all_signals:\n",
    "    # Combine all signals into a single DataFrame\n",
    "    combined_signals = pd.concat(all_signals, ignore_index=True)\n",
    "\n",
    "    # Ensure 'date' is of datetime type\n",
    "    combined_signals['date'] = pd.to_datetime(combined_signals['date'])\n",
    "\n",
    "    # Filter combined signals for the desired date range (split date to end date)\n",
    "    filtered_signals = combined_signals[(combined_signals['date'] >= split_date) & (combined_signals['date'] <= end_date)]\n",
    "\n",
    "    # Pivot the dataframe to have dates as rows and tickers as columns\n",
    "    pivoted_signals = filtered_signals.pivot(index='date', columns='ticker', values='signal')\n",
    "\n",
    "    # Optional: Replace NaN with 'hold' or any default signal\n",
    "    pivoted_signals.fillna('hold', inplace=True)\n",
    "\n",
    "    # Save the pivoted dataframe to a CSV file\n",
    "    pivoted_signals.to_csv('trading_signals.csv')\n",
    "    print(\"\\nPivoted trading signals (split to end) saved to 'trading_signals.csv'\")\n",
    "\n",
    "    # Display the first few rows of the pivoted dataframe\n",
    "    print(\"\\nPivoted Trading Signals:\")\n",
    "    print(pivoted_signals.head())\n",
    "else:\n",
    "    print(\"No signals were generated.\")"
   ],
   "id": "f74952a2583a1b7e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date ticker signal\n",
       "0 2024-01-02   AAPL   hold\n",
       "1 2024-01-03   AAPL   hold\n",
       "2 2024-01-04   AAPL   sell\n",
       "3 2024-01-05   AAPL   sell\n",
       "4 2024-01-08   AAPL   hold"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>hold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluate Signal Accuracy\n",
    "\n",
    "Compare the generated trading signals to actual stock price movements to assess their accuracy. For each 'buy' signal, check if the stock price increased the next day. For each 'sell' signal, check if the stock price decreased the next day. Calculate the accuracy metrics accordingly.\n"
   ],
   "id": "2c437425069d4439"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T18:53:31.445322Z",
     "start_time": "2024-12-04T18:53:30.998014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize a DataFrame to store evaluation results\n",
    "evaluation_results = []\n",
    "\n",
    "# Evaluate predictions vs actual data for January\n",
    "for ticker in tickers[:10]:\n",
    "    # Load the individual ticker signals with predictions and actuals\n",
    "    ticker_signals_path = f'signals/{ticker}_signals.csv'\n",
    "    if not os.path.exists(ticker_signals_path):\n",
    "        print(f\"\\nSignals file for {ticker} not found. Skipping evaluation.\")\n",
    "        continue\n",
    "\n",
    "    # Load the data\n",
    "    ticker_signals = pd.read_csv(ticker_signals_path, parse_dates=['date'])\n",
    "    if ticker_signals.empty:\n",
    "        print(f\"\\nNo signals found for {ticker}. Skipping evaluation.\")\n",
    "        continue\n",
    "\n",
    "    # Filter for January 2024\n",
    "    january_data = ticker_signals[(ticker_signals['date'] >= '2024-01-01') & (ticker_signals['date'] <= '2024-01-31')]\n",
    "\n",
    "    if january_data.empty:\n",
    "        print(f\"No data for January 2024 for {ticker}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae = (january_data['actual'] - january_data['prediction']).abs().mean()\n",
    "    mse = ((january_data['actual'] - january_data['prediction']) ** 2).mean()\n",
    "\n",
    "    # Append metrics to evaluation results\n",
    "    evaluation_results.append({'ticker': ticker, 'MAE': mae, 'MSE': mse})\n",
    "\n",
    "    # Plot actual vs predicted\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(january_data['date'], january_data['actual'], label='Actual Price', marker='o')\n",
    "    plt.plot(january_data['date'], january_data['prediction'], label='Predicted Price', linestyle='--', marker='x')\n",
    "    plt.title(f'{ticker} Actual vs Predicted Prices (January 2024)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Create a DataFrame for evaluation results\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "\n",
    "# Display results\n",
    "if not results_df.empty:\n",
    "    print(\"\\nEvaluation Metrics for January 2024:\")\n",
    "    print(results_df)\n",
    "else:\n",
    "    print(\"No evaluation results available for January 2024.\")"
   ],
   "id": "96c6b45ffe0ea178",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tickers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m evaluation_results \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Evaluate predictions vs actual data for January\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ticker \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtickers\u001B[49m[:\u001B[38;5;241m10\u001B[39m]:\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m# Load the individual ticker signals with predictions and actuals\u001B[39;00m\n\u001B[0;32m      7\u001B[0m     ticker_signals_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msignals/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mticker\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_signals.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(ticker_signals_path):\n",
      "\u001B[1;31mNameError\u001B[0m: name 'tickers' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "97f1481764613fef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
